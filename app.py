import streamlit as st
import pickle
import faiss
from sentence_transformers import SentenceTransformer
import numpy as np
import requests
import json
import torch

def chatbot_page():
    st.title("ü§ñ ·ª®NG D·ª§NG CHAT BOT")
    st.markdown("üí¨ H·ªèi ƒë√°p c√°c th√¥ng tin v·ªÅ c√¥ng ty/c·ªï phi·∫øu c·ªßa CMG v√† FPT.")

    # S·ª≠ d·ª•ng GPU n·∫øu c√≥, n·∫øu kh√¥ng th√¨ s·ª≠ d·ª•ng CPU
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    embed_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2", device=device)

    # ƒê·ªçc FAISS index v√† c√°c d·ªØ li·ªáu ƒë√£ l∆∞u tr·ªØ
    index = faiss.read_index("vector.index")

    with open("chunks.pkl", "rb") as f:
        chunk_texts = pickle.load(f)

    # L∆∞u tr·ªØ l·ªãch s·ª≠ c√°c cu·ªôc h·ªôi tho·∫°i trong session
    if "history" not in st.session_state:
        st.session_state.history = []

    # Nh·∫≠n c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
    query = st.chat_input("üí¨ Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:")

    if query:
        st.session_state.history.append({"question": query, "answer": "ƒêang x·ª≠ l√Ω..."})

        # M√£ h√≥a c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ t√¨m ki·∫øm trong FAISS index
        query_embedding = embed_model.encode([query], convert_to_numpy=True)
        D, I = index.search(query_embedding, 3)

        # N·ªëi c√°c vƒÉn b·∫£n t√¨m ƒë∆∞·ª£c t·ª´ FAISS index th√†nh m·ªôt ng·ªØ c·∫£nh
        # Ki·ªÉm tra n·∫øu chunk_texts[i] l√† chu·ªói, n·∫øu kh√¥ng th√¨ x·ª≠ l√Ω nh∆∞ Document
        try:
            context = "\n".join([chunk_texts[i] if isinstance(chunk_texts[i], str) else chunk_texts[i].page_content for i in I[0]])
        except Exception as e:
            st.error(f"ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu: {e}")
            return

        # G·ª≠i d·ªØ li·ªáu t·ªõi API ƒë·ªÉ l·∫•y c√¢u tr·∫£ l·ªùi t·ª´ AI
        url = 'http://localhost:1234/v1/chat/completions'
        data = {
            'temperature': 0.3,
            'max_tokens': 1024,
            'messages': [
                {
                    'role': 'system',
                    'content': (
                        "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI c√≥ nhi·ªám v·ª• ph√¢n t√≠ch n·ªôi dung t√†i li·ªáu v√† ƒë∆∞a ra c√¢u tr·∫£ l·ªùi r√µ r√†ng, chi ti·∫øt"
                        "Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n n·ªôi dung t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p. "
                        "N√™u l√™n ƒëi·ªÉm ch√≠nh trong vƒÉn b·∫£n."
                        "Kh√¥ng b·ªè s√≥t th√¥ng tin quan tr·ªçng."
                    )
                },
                {
                    'role': 'user',
                    'content': f"ƒê√¢y l√† n·ªôi dung t√†i li·ªáu tham kh·∫£o:\n\n{context}"
                },
                {
                    'role': 'user',
                    'content': (
                        f"C√¢u h·ªèi: {query}\n\n"
                        "Y√™u c·∫ßu: H√£y tr√¨nh b√†y r√µ r√†ng t√¨nh h√¨nh t√†i ch√≠nh, ho·∫°t ƒë·ªông ƒë·∫ßu t∆∞ v√† c·∫•u tr√∫c v·ªën, c·ªï t·ª©c c·ªßa c√¥ng ty n·∫øu c√≥. "
                        "G·ªìm c·∫£ c√°c s·ªë li·ªáu v·ªÅ doanh thu, l·ª£i nhu·∫≠n, ƒë·∫ßu t∆∞, c·ªï t·ª©c n·∫øu vƒÉn b·∫£n cung c·∫•p. "
                        "Tr√°nh tr·∫£ l·ªùi chung chung ho·∫∑c b·ªè s√≥t th√¥ng tin."
                    )
                }
            ]
        }

        headers = {'Content-Type': 'application/json'}
        response = requests.post(url, data=json.dumps(data), headers=headers)

        if response.status_code == 200:
            answer = response.json()['choices'][0]['message']['content']
            st.session_state.history[-1]["answer"] = answer
        else:
            st.session_state.history[-1]["answer"] = f"L·ªói t·ª´ API: {response.text}"

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ h·ªôi tho·∫°i
    for item in reversed(st.session_state.history):
        st.markdown(f"**üßë B·∫°n:** {item['question']}")
        st.markdown(f"**ü§ñ Tr·∫£ l·ªùi:** {item['answer']}")
        st.markdown("---")